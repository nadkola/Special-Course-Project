"""
data_utils.py — Data loading, schema introspection, and OLAP helper functions.

This module provides:
  • cached CSV loading via Streamlit
  • automatic schema / summary generation for the LLM prompt
  • pre-built OLAP helper functions (slice, dice, drill-down, roll-up, compare)
    that can be called directly OR whose logic is generated by the LLM
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path

# ────────────────────────────────────────────────────────────
# 1. DATA LOADING (cached so it only reads the CSV once)
# ────────────────────────────────────────────────────────────

DATA_PATH = Path(__file__).parent / "data" / "global_retail_sales.csv"


@st.cache_data
def load_data() -> pd.DataFrame:
    """Load the Global Retail Sales dataset and ensure correct types."""
    df = pd.read_csv(DATA_PATH, parse_dates=["order_date"])
    # Enforce categorical columns for efficiency
    cat_cols = [
        "region", "country", "category", "subcategory",
        "customer_segment", "quarter", "month_name",
    ]
    for col in cat_cols:
        df[col] = df[col].astype("category")
    df["year"] = df["year"].astype(int)
    df["month"] = df["month"].astype(int)
    return df


# ────────────────────────────────────────────────────────────
# 2. SCHEMA / SUMMARY GENERATION (fed into the LLM prompt)
# ────────────────────────────────────────────────────────────

def get_schema_description(df: pd.DataFrame) -> str:
    """Return a compact textual schema that the LLM can use to write pandas code."""
    lines = [
        "=== DATASET SCHEMA: global_retail_sales ===",
        f"Rows: {len(df):,}  |  Columns: {len(df.columns)}",
        f"Date range: {df['order_date'].min().date()} to {df['order_date'].max().date()}",
        "",
        "COLUMNS (name — dtype — example values):",
    ]
    for col in df.columns:
        nuniq = df[col].nunique()
        if nuniq <= 12:
            vals = ", ".join(str(v) for v in sorted(df[col].dropna().unique())[:12])
        else:
            vals = ", ".join(str(v) for v in df[col].dropna().head(4)) + " …"
        lines.append(f"  {col:20s}  {str(df[col].dtype):15s}  unique={nuniq:<6}  [{vals}]")

    lines += [
        "",
        "DIMENSION HIERARCHIES:",
        "  Time      :  year → quarter → month (month_name) → order_date",
        "  Geography  :  region → country",
        "  Product    :  category → subcategory",
        "  Customer   :  customer_segment",
        "",
        "MEASURES (numeric columns to aggregate):",
        "  quantity, unit_price, revenue, cost, profit, profit_margin",
        "",
        "KEY RELATIONSHIPS:",
        "  revenue = quantity × unit_price",
        "  profit  = revenue − cost",
        "  profit_margin = (profit / revenue) × 100",
    ]
    return "\n".join(lines)


def get_dataset_overview(df: pd.DataFrame) -> dict:
    """Return summary statistics for the Dataset Overview panel."""
    return {
        "total_rows": len(df),
        "date_range": f"{df['order_date'].min().date()} to {df['order_date'].max().date()}",
        "total_revenue": df["revenue"].sum(),
        "total_profit": df["profit"].sum(),
        "avg_profit_margin": df["profit_margin"].mean(),
        "regions": sorted(df["region"].unique().tolist()),
        "categories": sorted(df["category"].unique().tolist()),
        "segments": sorted(df["customer_segment"].unique().tolist()),
        "countries_count": df["country"].nunique(),
        "years": sorted(df["year"].unique().tolist()),
    }


# ────────────────────────────────────────────────────────────
# 3. OLAP HELPER FUNCTIONS
# ────────────────────────────────────────────────────────────

def olap_slice(df: pd.DataFrame, column: str, value) -> pd.DataFrame:
    """SLICE — filter on a single dimension value."""
    return df[df[column] == value].copy()


def olap_dice(df: pd.DataFrame, filters: dict) -> pd.DataFrame:
    """DICE — filter on multiple dimension values.
    filters: {column: value_or_list, ...}
    """
    result = df.copy()
    for col, val in filters.items():
        if isinstance(val, list):
            result = result[result[col].isin(val)]
        else:
            result = result[result[col] == val]
    return result


def olap_group_summarize(
    df: pd.DataFrame,
    group_cols: list[str],
    agg_dict: dict | None = None,
) -> pd.DataFrame:
    """GROUP & SUMMARIZE — aggregate measures by given dimensions."""
    if agg_dict is None:
        agg_dict = {
            "revenue": "sum",
            "profit": "sum",
            "quantity": "sum",
            "cost": "sum",
        }
    result = df.groupby(group_cols, observed=True).agg(agg_dict).reset_index()
    if "revenue" in result.columns and "profit" in result.columns:
        result["profit_margin"] = round(result["profit"] / result["revenue"] * 100, 2)
    return result.sort_values(list(agg_dict.keys())[0], ascending=False)


def olap_drilldown(
    df: pd.DataFrame,
    hierarchy: list[str],
    current_level: int,
    filter_value=None,
) -> pd.DataFrame:
    """DRILL-DOWN — go from a summary level to the next detail level.
    hierarchy: e.g. ['year','quarter','month']
    current_level: index into hierarchy (0 = top)
    filter_value: value to filter at current_level before drilling down
    """
    if current_level >= len(hierarchy) - 1:
        return df  # already at leaf
    current_col = hierarchy[current_level]
    next_col = hierarchy[current_level + 1]
    subset = df.copy()
    if filter_value is not None:
        subset = subset[subset[current_col] == filter_value]
    return olap_group_summarize(subset, [next_col])


def olap_compare(
    df: pd.DataFrame,
    dimension: str,
    values: list,
    measures: list[str] | None = None,
) -> pd.DataFrame:
    """COMPARE — side-by-side comparison of dimension values."""
    if measures is None:
        measures = ["revenue", "profit", "quantity"]
    subset = df[df[dimension].isin(values)]
    result = subset.groupby(dimension, observed=True)[measures].sum().reset_index()
    # Add percentage change if exactly 2 values
    if len(values) == 2 and len(result) == 2:
        for m in measures:
            v0, v1 = result[m].iloc[0], result[m].iloc[1]
            pct = round((v1 - v0) / v0 * 100, 2) if v0 != 0 else None
            result[f"{m}_change_%"] = [None, pct]
    return result
